{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from scipy.special import expit\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('svm_model3.npy')\n",
    "\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "scale = 0\n",
    "detections = []\n",
    "\n",
    "(winW, winH) = (64,128)  # size of the sliding window\n",
    "windowSize = (winW,winH)\n",
    "downscale = 1.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y: y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('C:\\\\Users\\\\admin\\\\JupyterNotebook_works\\\\mtech-programing-labs\\\\S2\\\\Computer-vision\\\\Project\\\\detection\\\\inputs\\\\1\\\\184.png')\n",
    "img = cv2.resize(img,(300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection:: Location -> (30, 20)\n",
      "Scale ->  23 | Confidence Score [3.29705529] | Prob: [0.96432765]\n",
      "\n",
      "Detection:: Location -> (50, 20)\n",
      "Scale ->  23 | Confidence Score [2.91674428] | Prob: [0.94866799]\n",
      "\n",
      "Detection:: Location -> (70, 20)\n",
      "Scale ->  23 | Confidence Score [2.41205048] | Prob: [0.91774161]\n",
      "\n",
      "Detection:: Location -> (90, 20)\n",
      "Scale ->  23 | Confidence Score [2.20941678] | Prob: [0.90109196]\n",
      "\n",
      "Detection:: Location -> (60, 30)\n",
      "Scale ->  23 | Confidence Score [2.42179848] | Prob: [0.91847451]\n",
      "\n",
      "Detection:: Location -> (80, 30)\n",
      "Scale ->  23 | Confidence Score [2.93968323] | Prob: [0.94977362]\n",
      "\n",
      "Detection:: Location -> (140, 40)\n",
      "Scale ->  23 | Confidence Score [2.41257774] | Prob: [0.9177814]\n",
      "\n",
      "Detection:: Location -> (60, 50)\n",
      "Scale ->  23 | Confidence Score [4.35214121] | Prob: [0.98728456]\n",
      "\n",
      "Detection:: Location -> (210, 70)\n",
      "Scale ->  23 | Confidence Score [2.40045741] | Prob: [0.91686218]\n",
      "\n",
      "Detection:: Location -> (20, 0)\n",
      "Scale ->  24 | Confidence Score [2.84347208] | Prob: [0.94498026]\n",
      "\n",
      "Detection:: Location -> (40, 0)\n",
      "Scale ->  24 | Confidence Score [2.25158481] | Prob: [0.90478715]\n",
      "\n",
      "Detection:: Location -> (10, 10)\n",
      "Scale ->  24 | Confidence Score [2.20754324] | Prob: [0.90092485]\n",
      "\n",
      "Detection:: Location -> (20, 10)\n",
      "Scale ->  24 | Confidence Score [2.72927209] | Prob: [0.93873199]\n",
      "\n",
      "Detection:: Location -> (100, 10)\n",
      "Scale ->  24 | Confidence Score [3.94767161] | Prob: [0.98106584]\n",
      "\n",
      "Detection:: Location -> (40, 20)\n",
      "Scale ->  24 | Confidence Score [2.95175147] | Prob: [0.9503462]\n",
      "\n",
      "Detection:: Location -> (60, 20)\n",
      "Scale ->  24 | Confidence Score [4.20926428] | Prob: [0.98536021]\n",
      "\n",
      "Detection:: Location -> (40, 30)\n",
      "Scale ->  24 | Confidence Score [3.84858395] | Prob: [0.97913475]\n",
      "\n",
      "Detection:: Location -> (30, 0)\n",
      "Scale ->  25 | Confidence Score [3.86379545] | Prob: [0.97944326]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for resized in pyramid_gaussian(img, downscale=downscale): # loop over each layer of the image that you take\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "    for (x,y,window_) in sliding_window(resized, stepSize=10, windowSize=(winW,winH)):\n",
    "        # if the window does not meet our desired window size, ignore it!\n",
    "        if window_.shape[0] != winH or window_.shape[1] !=winW or window_.shape[2]!=3: # ensure the sliding window has met the minimum size requirement\n",
    "            continue\n",
    "        window = color.rgb2gray(window_)\n",
    "        #window = cv2.cvtColor(window_, cv2.COLOR_BGR2GRAY) #.rgb2gray(window_[:,:,:3])\n",
    "        fds = hog(window, orientations, pixels_per_cell, cells_per_block, block_norm='L2')  # extract HOG features from the window captured\n",
    "        fds = fds.reshape(1, -1) # re shape the image to make a silouhette of hog\n",
    "        pred = model.predict(fds) # use the SVM model to make a prediction on the HOG features extracted from the window\n",
    "        \n",
    "        if pred == 1:\n",
    "            if expit(model.decision_function(fds))>=0.90: #model.decision_function(fds) > 1.5:  # set a threshold value for the SVM prediction i.e. only firm the predictions above probability of 0.6\n",
    "                print(\"Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                print(\"Scale ->  {} | Confidence Score {} | Prob: {}\\n\".format(scale ,model.decision_function(fds),\n",
    "                                                                              expit(model.decision_function(fds))))\n",
    "                detections.append((int(x * (downscale**scale)), int(y * (downscale**scale)), model.decision_function(fds),\n",
    "                                   int(windowSize[0]*(downscale**scale)), # create a list of all the predictions found\n",
    "                                      int(windowSize[1]*(downscale**scale))))\n",
    "                \n",
    "    scale+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection confidence score:  [3.297055289310304, 2.0570444926431533, 2.9167442757767343, 2.412050483454074, 2.2094167810308356, 2.4217984762426914, 2.939683227285977, 2.0529073108730946, 2.4125777357920386, 1.8916673424122061, 1.83619632902814, 4.3521412070361825, 2.0047304212279453, 1.8539867918040924, 1.9491144567290553, 2.047090819672328, 2.4004574111101586, 2.843472080331523, 2.251584806672958, 2.2075432401555, 2.7292720870629488, 2.1029234888506227, 3.947671607426921, 2.9517514720197875, 4.20926427658979, 3.848583949269905, 2.0436891093743945, 2.0948363991207932, 3.8637954494324536, 2.113745214265828, 3.297055289310304, 2.9167442757767343, 2.412050483454074, 2.2094167810308356, 2.4217984762426914, 2.939683227285977, 2.4125777357920386, 4.3521412070361825, 2.4004574111101586, 2.843472080331523, 2.251584806672958, 2.2075432401555, 2.7292720870629488, 3.947671607426921, 2.9517514720197875, 4.20926427658979, 3.848583949269905, 3.8637954494324536]\n"
     ]
    }
   ],
   "source": [
    "rects = np.array([[x, y, x + w, y + h] for (x, y, _, w, h) in detections]) # do nms on the detected bounding boxes\n",
    "sc = [score[0] for (x, y, score, w, h) in detections]\n",
    "print(\"detection confidence score: \", sc)\n",
    "sc = np.array(sc)\n",
    "nms_rects = non_max_suppression(rects, probs = sc, overlapThresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,   0,  74, 128],\n",
       "       [ 20,   0,  84, 128],\n",
       "       [ 10,  10,  74, 138],\n",
       "       [ 10,  20,  74, 148],\n",
       "       [ 20,  20,  84, 148],\n",
       "       [ 40,  60, 104, 188],\n",
       "       [125,  37, 205, 197]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_sc = []\n",
    "for i in range(rects.shape[0]):\n",
    "    for j in range(nms_rects.shape[0]):\n",
    "        if np.array_equal(rects[i], nms_rects[j]):\n",
    "            nms_sc.append(sc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   60,    50,   124,   178],\n",
       "       [10164,  8470, 21006, 30154],\n",
       "       [21175,  2117, 34727, 29222],\n",
       "       [  125,    12,   205,   172],\n",
       "       [  210,    70,   274,   198],\n",
       "       [35575, 11858, 46417, 33542]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i, (xA, yA, xB, yB) in enumerate(nms_rects):\n",
    "    print(i)\n",
    "    cv2.rectangle(img, (xA, yA), (xB, yB), (0,255,0), 2)\n",
    "    cv2.putText(img,'Human',(xA-2,yA-2),1,0.75,(255,255,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Detection', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('svm_model3.npy')\n",
    "\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "(winW, winH) = (64,128)  # size of the sliding window\n",
    "windowSize = (winW,winH)\n",
    "downscale = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y: y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img):\n",
    "    scale = 0\n",
    "    detections = []\n",
    "    for resized in pyramid_gaussian(img, downscale=downscale): # loop over each layer of the image that you take\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "        for (x,y,window_) in sliding_window(resized, stepSize=10, windowSize=(winW,winH)):\n",
    "            # if the window does not meet our desired window size, ignore it!\n",
    "            if window_.shape[0] != winH or window_.shape[1] !=winW or window_.shape[2]!=3: # ensure the sliding window has met the minimum size requirement\n",
    "                continue\n",
    "            window = color.rgb2gray(window_)\n",
    "            #window = cv2.cvtColor(window_, cv2.COLOR_BGR2GRAY) #.rgb2gray(window_[:,:,:3])\n",
    "            fds = hog(window, orientations, pixels_per_cell, cells_per_block, block_norm='L2')  # extract HOG features from the window captured\n",
    "            fds = fds.reshape(1, -1) # re shape the image to make a silouhette of hog\n",
    "            pred = model.predict(fds) # use the SVM model to make a prediction on the HOG features extracted from the window\n",
    "\n",
    "            if pred == 1:\n",
    "                if expit(model.decision_function(fds))>=0.90:  # set a threshold value for the SVM prediction i.e. only firm the predictions above probability of 0.6\n",
    "                    #print(\"Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                    #print(\"Scale ->  {} | Confidence Score {} \\n\".format(scale,model.decision_function(fds)))\n",
    "                    detections.append((int(x * (downscale**scale)), int(y * (downscale**scale)), expit(model.decision_function(fds)),\n",
    "                                       int(windowSize[0]*(downscale**scale)), # create a list of all the predictions found\n",
    "                                          int(windowSize[1]*(downscale**scale))))\n",
    "        scale+=1\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957789328776077\n",
      "0.9704486316797872\n",
      "0.9312274295354676\n",
      "0.9591005031987316\n",
      "0.9860022500585525\n",
      "0.9806327861730264\n",
      "0.9325644804403296\n",
      "0.9522511174307254\n",
      "0.9748141358862494\n",
      "0.9236439375402665\n",
      "0.9520616264625686\n",
      "0.9036837241764731\n",
      "0.9648980279395281\n",
      "0.913444847194971\n",
      "0.9605705261721993\n",
      "0.9330804094996304\n",
      "0.9124567953132977\n",
      "0.932642274110466\n",
      "0.979741780821027\n",
      "0.939784206819394\n",
      "0.9676190278751077\n",
      "0.9173055999596768\n",
      "0.9612146614686199\n",
      "0.9277648362746053\n",
      "0.9393343242991016\n",
      "0.9449443046422201\n",
      "0.9830175968917747\n",
      "0.9335018689224741\n",
      "0.9656208045943705\n",
      "0.9526718612936019\n",
      "0.9183340211246398\n",
      "0.9516373880279752\n",
      "0.9376628947068532\n",
      "0.9474568591355822\n",
      "0.9777591590581719\n",
      "0.9070233593128145\n",
      "0.9857714183074272\n",
      "0.9111959629468953\n",
      "0.9748431252215864\n",
      "0.9686283643975245\n",
      "0.9801399415243384\n",
      "0.9253172776081089\n",
      "0.9151633379941528\n",
      "0.9583750457615737\n",
      "0.9348193716496606\n",
      "0.9632319073430883\n",
      "0.9464098903414947\n",
      "0.9258388743065451\n",
      "0.9333173831319305\n",
      "0.9067422421244282\n",
      "0.9806802744430391\n",
      "0.9858882870042992\n",
      "0.9228606571921355\n",
      "0.9900105306057897\n",
      "0.9485850449172166\n",
      "0.9262954074955144\n",
      "0.9023346475349127\n",
      "0.9186308390440211\n",
      "0.9445660600374703\n",
      "0.9779301416128504\n",
      "0.9591065086292819\n",
      "0.9679247867051755\n",
      "0.9206021891089943\n",
      "0.9110382295535961\n",
      "0.9726009495061485\n",
      "0.9315041182075566\n",
      "0.9030098083599241\n",
      "0.9027013389264639\n",
      "0.9710888455533581\n",
      "0.9032535400928424\n",
      "0.9536619618821403\n",
      "0.9263021613817065\n",
      "0.9532504904800031\n",
      "0.9430629111850088\n",
      "0.9025906964901572\n",
      "0.9317562147140431\n",
      "0.9705563709892131\n",
      "0.9077972445559074\n",
      "0.9644032467308185\n",
      "0.9975316050747493\n",
      "0.9520143534055701\n",
      "0.9690633558377573\n",
      "0.9752201515828016\n",
      "0.9243639609973049\n",
      "0.9187600043611981\n",
      "0.940557312606072\n",
      "0.9791859741196939\n",
      "0.9449682511678044\n",
      "0.948941157631377\n",
      "0.9338229312045211\n",
      "0.9053457301994964\n",
      "0.9580587789919335\n",
      "0.9328386381941549\n",
      "0.9241543641724801\n",
      "0.9600994124346652\n",
      "0.9412504548168158\n",
      "0.9028668493397428\n",
      "0.9698304652600195\n",
      "0.9583959794011181\n",
      "0.938084689702089\n",
      "0.9232190440990503\n",
      "0.9205837924939826\n",
      "0.9290110403599218\n",
      "0.9627745432096773\n",
      "0.937332998387483\n",
      "0.9275675866435993\n",
      "0.9417258642074376\n",
      "0.9174380957020286\n",
      "0.9820674803585813\n",
      "0.9754667869606314\n",
      "0.9360265724747184\n",
      "0.9833519439220556\n",
      "0.9263277177231365\n",
      "0.9205331750379725\n",
      "0.9363202621036798\n",
      "0.9297810809467413\n",
      "0.93436215643877\n",
      "0.9123071706266135\n",
      "0.9469503073547954\n",
      "0.969557392703166\n",
      "0.9494101786248301\n",
      "0.9496075332144707\n",
      "0.9765773898423769\n",
      "0.9448311053173897\n",
      "0.9692657329591206\n",
      "0.9844032328822483\n",
      "0.9425785496737651\n",
      "0.941884005911193\n",
      "0.9530363470142076\n",
      "0.9167215082331622\n",
      "0.934669740163584\n",
      "0.9445502585604812\n",
      "0.9225816691887601\n",
      "0.9628771380741373\n",
      "0.9774485480095377\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "#cap = cv2.VideoCapture('C:\\\\Users\\\\admin\\\\JupyterNotebook_works\\\\mtech-programing-labs\\\\S2\\\\Computer-vision\\\\Project\\\\detection\\\\videoplayback.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame_res = cv2.resize(frame,(300,200))\n",
    "        detections = detect(frame_res)\n",
    "        rects = np.array([[x, y, x + w, y + h] for (x, y, _, w, h) in detections]) # do nms on the detected bounding boxes\n",
    "        sc = [score[0] for (x, y, score, w, h) in detections]\n",
    "        sc = np.array(sc)\n",
    "        nms_rects = non_max_suppression(rects, probs = sc, overlapThresh=0.3)\n",
    "        nms_sc = []\n",
    "        for i in range(rects.shape[0]):\n",
    "            for j in range(nms_rects.shape[0]):\n",
    "                if np.array_equal(rects[i], nms_rects[j]):\n",
    "                    nms_sc.append(sc[i])\n",
    "        nms_sc = np.array(nms_sc)\n",
    "        \n",
    "        for i, (xA, yA, xB, yB) in enumerate(nms_rects):\n",
    "            cv2.rectangle(frame_res, (xA, yA), (xB, yB), (0,255,0), 2)\n",
    "            cv2.putText(frame_res,'Human',(xA-2,yA-2),1,0.75,(255,255,0),1)\n",
    "            print(nms_sc[i])\n",
    "            \n",
    "        cv2.imshow('frame', frame_res)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
